{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"17AHVibvmd9vqafxudOstD7VRxqJviXE1","authorship_tag":"ABX9TyOvfDAHh8aENdvgR8OX5CZZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f-45g0kS8Npw","executionInfo":{"status":"ok","timestamp":1690521453114,"user_tz":-540,"elapsed":14,"user":{"displayName":"논문논문","userId":"03109390045991028253"}},"outputId":"d56b2545-ae10-41d3-d89a-918d0df10c73"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Quantization/myDoReFa\n"]}],"source":["%cd /content/drive/MyDrive/Quantization/myDoReFa"]},{"cell_type":"code","source":["!python main.py --epoch 200 --W 1 --A 2 --G 6 --gradient_quantize True"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7y0RS2dk8c9N","executionInfo":{"status":"ok","timestamp":1689922422160,"user_tz":-540,"elapsed":17692,"user":{"displayName":"논문논문","userId":"03109390045991028253"}},"outputId":"abb6082c-a360-4bcc-a157-9f138ce9e196"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Quantization Bits\n","\n","Weight: 1\n","Activation: 2\n","Gradient: 6\n","Gradient_Quantize : True\n","  0% 0/391 [00:00<?, ?it/s]Step : 0, Loss : 2.3876\n","  0% 1/391 [00:01<07:42,  1.18s/it]Step : 1, Loss : nan\n","  1% 2/391 [00:02<06:48,  1.05s/it]Step : 2, Loss : nan\n","  1% 3/391 [00:02<06:12,  1.04it/s]Step : 3, Loss : nan\n","  1% 4/391 [00:03<05:46,  1.12it/s]Step : 4, Loss : nan\n","  1% 5/391 [00:04<05:33,  1.16it/s]Step : 5, Loss : nan\n","  2% 6/391 [00:05<05:27,  1.18it/s]Step : 6, Loss : nan\n","  2% 7/391 [00:06<05:20,  1.20it/s]Step : 7, Loss : nan\n","  2% 8/391 [00:07<05:16,  1.21it/s]Step : 8, Loss : nan\n","  2% 9/391 [00:07<05:11,  1.22it/s]Step : 9, Loss : nan\n","  3% 10/391 [00:08<05:11,  1.22it/s]Step : 10, Loss : nan\n","  3% 11/391 [00:09<05:38,  1.12it/s]\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n","    data = self._next_data()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 677, in _next_data\n","    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n","    data = [self.dataset[idx] for idx in possibly_batched_index]\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n","    data = [self.dataset[idx] for idx in possibly_batched_index]\n","  File \"/usr/local/lib/python3.10/dist-packages/torchvision/datasets/cifar.py\", line 118, in __getitem__\n","    img = self.transform(img)\n","  File \"/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\", line 95, in __call__\n","    img = t(img)\n","  File \"/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\", line 137, in __call__\n","    return F.to_tensor(pic)\n","  File \"/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\", line 166, in to_tensor\n","    img = torch.from_numpy(np.array(pic, mode_to_nptype.get(pic.mode, np.uint8), copy=True))\n","  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 700, in __array__\n","    class ArrayData:\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Quantization/myDoReFa/main.py\", line 117, in <module>\n","    main(args)\n","  File \"/content/drive/MyDrive/Quantization/myDoReFa/main.py\", line 89, in main\n","    train(args,epoch,train_loader,model,optimizer,lr_scheduler,criterion)\n","  File \"/content/drive/MyDrive/Quantization/myDoReFa/main.py\", line 32, in train\n","    for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n","  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1178, in __iter__\n","    for obj in iterable:\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n","    data = self._next_data()\n","KeyboardInterrupt\n","^C\n"]}]},{"cell_type":"code","source":["!python main.py --epoch 200 --W 32 --A 32 --G 32"],"metadata":{"id":"5l--RjqZ83xC","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e0010ac8-e66c-47fd-ad26-81a4fb3a464b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Quantization Bits\n","\n","Weight: 32\n","Activation: 32\n","Gradient: 32\n","Gradient_Quantize : False\n","/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n","/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","100% 391/391 [00:49<00:00,  7.83it/s]\n","Epoch : 1, Loss Avg : 1.5100\n","100% 79/79 [00:03<00:00, 23.50it/s]\n","Accuracy : 54 %\n","100% 391/391 [00:49<00:00,  7.83it/s]\n","Epoch : 2, Loss Avg : 1.0588\n","100% 79/79 [00:03<00:00, 23.29it/s]\n","Accuracy : 60 %\n","100% 391/391 [00:49<00:00,  7.84it/s]\n","Epoch : 3, Loss Avg : 0.8784\n","100% 79/79 [00:03<00:00, 23.92it/s]\n","Accuracy : 59 %\n","100% 391/391 [00:50<00:00,  7.76it/s]\n","Epoch : 4, Loss Avg : 0.7750\n","100% 79/79 [00:03<00:00, 23.42it/s]\n","Accuracy : 69 %\n","100% 391/391 [00:49<00:00,  7.84it/s]\n","Epoch : 5, Loss Avg : 0.7025\n","100% 79/79 [00:03<00:00, 21.28it/s]\n","Accuracy : 78 %\n","100% 391/391 [00:49<00:00,  7.90it/s]\n","Epoch : 6, Loss Avg : 0.6436\n","100% 79/79 [00:04<00:00, 19.59it/s]\n","Accuracy : 75 %\n","100% 391/391 [00:48<00:00,  8.06it/s]\n","Epoch : 7, Loss Avg : 0.6025\n","100% 79/79 [00:03<00:00, 20.75it/s]\n","Accuracy : 74 %\n","100% 391/391 [00:48<00:00,  8.06it/s]\n","Epoch : 8, Loss Avg : 0.5663\n","100% 79/79 [00:03<00:00, 24.04it/s]\n","Accuracy : 78 %\n","100% 391/391 [00:49<00:00,  7.95it/s]\n","Epoch : 9, Loss Avg : 0.5312\n","100% 79/79 [00:03<00:00, 24.18it/s]\n","Accuracy : 80 %\n","100% 391/391 [00:49<00:00,  7.91it/s]\n","Epoch : 10, Loss Avg : 0.5108\n","100% 79/79 [00:03<00:00, 24.22it/s]\n","Accuracy : 81 %\n","100% 391/391 [00:49<00:00,  7.95it/s]\n","Epoch : 11, Loss Avg : 0.4924\n","100% 79/79 [00:03<00:00, 22.22it/s]\n","Accuracy : 80 %\n","100% 391/391 [00:48<00:00,  8.09it/s]\n","Epoch : 12, Loss Avg : 0.4700\n","100% 79/79 [00:04<00:00, 18.51it/s]\n","Accuracy : 81 %\n","100% 391/391 [00:49<00:00,  7.89it/s]\n","Epoch : 13, Loss Avg : 0.4581\n","100% 79/79 [00:04<00:00, 18.63it/s]\n","Accuracy : 80 %\n","100% 391/391 [00:49<00:00,  7.92it/s]\n","Epoch : 14, Loss Avg : 0.4389\n","100% 79/79 [00:03<00:00, 21.13it/s]\n","Accuracy : 83 %\n","100% 391/391 [00:49<00:00,  7.90it/s]\n","Epoch : 15, Loss Avg : 0.4188\n","100% 79/79 [00:03<00:00, 24.52it/s]\n","Accuracy : 84 %\n","100% 391/391 [00:49<00:00,  7.85it/s]\n","Epoch : 16, Loss Avg : 0.4082\n","100% 79/79 [00:03<00:00, 23.91it/s]\n","Accuracy : 79 %\n","100% 391/391 [00:49<00:00,  7.87it/s]\n","Epoch : 17, Loss Avg : 0.3971\n","100% 79/79 [00:03<00:00, 23.83it/s]\n","Accuracy : 83 %\n","100% 391/391 [00:49<00:00,  7.90it/s]\n","Epoch : 18, Loss Avg : 0.3831\n","100% 79/79 [00:03<00:00, 24.41it/s]\n","Accuracy : 83 %\n","100% 391/391 [00:48<00:00,  8.02it/s]\n","Epoch : 19, Loss Avg : 0.3708\n","100% 79/79 [00:03<00:00, 19.84it/s]\n","Accuracy : 84 %\n","100% 391/391 [00:48<00:00,  8.06it/s]\n","Epoch : 20, Loss Avg : 0.3611\n","100% 79/79 [00:04<00:00, 19.16it/s]\n","Accuracy : 85 %\n","100% 391/391 [00:48<00:00,  8.05it/s]\n","Epoch : 21, Loss Avg : 0.3533\n","100% 79/79 [00:03<00:00, 23.97it/s]\n","Accuracy : 84 %\n","100% 391/391 [00:49<00:00,  7.89it/s]\n","Epoch : 22, Loss Avg : 0.3432\n","100% 79/79 [00:03<00:00, 24.68it/s]\n","Accuracy : 84 %\n","100% 391/391 [00:49<00:00,  7.94it/s]\n","Epoch : 23, Loss Avg : 0.3367\n","100% 79/79 [00:03<00:00, 24.35it/s]\n","Accuracy : 85 %\n","100% 391/391 [00:49<00:00,  7.93it/s]\n","Epoch : 24, Loss Avg : 0.3300\n","100% 79/79 [00:03<00:00, 23.64it/s]\n","Accuracy : 84 %\n","100% 391/391 [00:49<00:00,  7.91it/s]\n","Epoch : 25, Loss Avg : 0.3199\n","100% 79/79 [00:03<00:00, 20.45it/s]\n","Accuracy : 84 %\n","100% 391/391 [00:49<00:00,  7.92it/s]\n","Epoch : 26, Loss Avg : 0.3116\n","100% 79/79 [00:04<00:00, 18.52it/s]\n","Accuracy : 85 %\n","100% 391/391 [00:49<00:00,  7.97it/s]\n","Epoch : 27, Loss Avg : 0.3028\n","100% 79/79 [00:03<00:00, 19.98it/s]\n","Accuracy : 86 %\n","100% 391/391 [00:48<00:00,  8.02it/s]\n","Epoch : 28, Loss Avg : 0.2950\n","100% 79/79 [00:03<00:00, 24.04it/s]\n","Accuracy : 85 %\n","100% 391/391 [00:49<00:00,  7.97it/s]\n","Epoch : 29, Loss Avg : 0.2919\n","100% 79/79 [00:03<00:00, 24.03it/s]\n","Accuracy : 85 %\n","100% 391/391 [00:49<00:00,  7.96it/s]\n","Epoch : 30, Loss Avg : 0.2855\n","100% 79/79 [00:03<00:00, 24.61it/s]\n","Accuracy : 85 %\n","100% 391/391 [00:48<00:00,  8.01it/s]\n","Epoch : 31, Loss Avg : 0.2804\n","100% 79/79 [00:03<00:00, 21.34it/s]\n","Accuracy : 86 %\n","100% 391/391 [00:47<00:00,  8.17it/s]\n","Epoch : 32, Loss Avg : 0.2778\n","100% 79/79 [00:04<00:00, 18.67it/s]\n","Accuracy : 85 %\n","100% 391/391 [00:48<00:00,  8.11it/s]\n","Epoch : 33, Loss Avg : 0.2685\n","100% 79/79 [00:03<00:00, 23.82it/s]\n","Accuracy : 85 %\n","100% 391/391 [00:49<00:00,  7.97it/s]\n","Epoch : 34, Loss Avg : 0.2680\n","100% 79/79 [00:03<00:00, 24.06it/s]\n","Accuracy : 87 %\n","100% 391/391 [00:49<00:00,  7.94it/s]\n","Epoch : 35, Loss Avg : 0.2630\n","100% 79/79 [00:03<00:00, 23.22it/s]\n","Accuracy : 85 %\n","100% 391/391 [00:49<00:00,  7.94it/s]\n","Epoch : 36, Loss Avg : 0.2548\n","100% 79/79 [00:03<00:00, 23.98it/s]\n","Accuracy : 84 %\n","100% 391/391 [00:49<00:00,  7.93it/s]\n","Epoch : 37, Loss Avg : 0.2515\n","100% 79/79 [00:03<00:00, 20.12it/s]\n","Accuracy : 86 %\n","100% 391/391 [00:49<00:00,  7.94it/s]\n","Epoch : 38, Loss Avg : 0.2484\n","100% 79/79 [00:04<00:00, 18.31it/s]\n","Accuracy : 86 %\n","100% 391/391 [00:49<00:00,  7.92it/s]\n","Epoch : 39, Loss Avg : 0.2455\n","100% 79/79 [00:04<00:00, 19.75it/s]\n","Accuracy : 86 %\n","100% 391/391 [00:49<00:00,  7.89it/s]\n","Epoch : 40, Loss Avg : 0.2361\n","100% 79/79 [00:03<00:00, 22.53it/s]\n","Accuracy : 86 %\n","100% 391/391 [00:49<00:00,  7.88it/s]\n","Epoch : 41, Loss Avg : 0.2322\n","100% 79/79 [00:03<00:00, 24.40it/s]\n","Accuracy : 86 %\n","100% 391/391 [00:49<00:00,  7.89it/s]\n","Epoch : 42, Loss Avg : 0.2323\n","100% 79/79 [00:03<00:00, 23.99it/s]\n","Accuracy : 87 %\n","100% 391/391 [00:49<00:00,  7.90it/s]\n","Epoch : 43, Loss Avg : 0.2266\n","100% 79/79 [00:03<00:00, 23.53it/s]\n","Accuracy : 87 %\n","100% 391/391 [00:50<00:00,  7.78it/s]\n","Epoch : 44, Loss Avg : 0.2160\n","100% 79/79 [00:03<00:00, 23.26it/s]\n","Accuracy : 87 %\n","100% 391/391 [00:49<00:00,  7.87it/s]\n","Epoch : 45, Loss Avg : 0.2198\n","100% 79/79 [00:03<00:00, 20.27it/s]\n","Accuracy : 85 %\n","100% 391/391 [00:49<00:00,  7.97it/s]\n","Epoch : 46, Loss Avg : 0.2204\n","100% 79/79 [00:04<00:00, 18.09it/s]\n","Accuracy : 87 %\n","100% 391/391 [00:49<00:00,  7.98it/s]\n","Epoch : 47, Loss Avg : 0.2135\n","100% 79/79 [00:03<00:00, 22.10it/s]\n","Accuracy : 86 %\n","100% 391/391 [00:49<00:00,  7.90it/s]\n","Epoch : 48, Loss Avg : 0.2152\n","100% 79/79 [00:03<00:00, 24.32it/s]\n","Accuracy : 87 %\n","100% 391/391 [00:49<00:00,  7.89it/s]\n","Epoch : 49, Loss Avg : 0.2070\n","100% 79/79 [00:03<00:00, 23.80it/s]\n","Accuracy : 86 %\n","100% 391/391 [00:50<00:00,  7.81it/s]\n","Epoch : 50, Loss Avg : 0.1992\n","100% 79/79 [00:03<00:00, 24.50it/s]\n","Accuracy : 87 %\n","100% 391/391 [00:50<00:00,  7.82it/s]\n","Epoch : 51, Loss Avg : 0.2013\n","100% 79/79 [00:03<00:00, 24.02it/s]\n","Accuracy : 87 %\n","100% 391/391 [00:49<00:00,  7.93it/s]\n","Epoch : 52, Loss Avg : 0.1998\n","100% 79/79 [00:03<00:00, 20.51it/s]\n","Accuracy : 87 %\n","100% 391/391 [00:49<00:00,  7.97it/s]\n","Epoch : 53, Loss Avg : 0.1887\n","100% 79/79 [00:04<00:00, 18.36it/s]\n","Accuracy : 87 %\n","100% 391/391 [00:48<00:00,  8.05it/s]\n","Epoch : 54, Loss Avg : 0.1884\n","100% 79/79 [00:03<00:00, 21.45it/s]\n","Accuracy : 86 %\n","100% 391/391 [00:48<00:00,  7.98it/s]\n","Epoch : 55, Loss Avg : 0.1859\n","100% 79/79 [00:03<00:00, 24.03it/s]\n","Accuracy : 85 %\n","100% 391/391 [00:49<00:00,  7.92it/s]\n","Epoch : 56, Loss Avg : 0.1850\n","100% 79/79 [00:03<00:00, 23.84it/s]\n","Accuracy : 87 %\n","100% 391/391 [00:50<00:00,  7.72it/s]\n","Epoch : 57, Loss Avg : 0.1850\n","100% 79/79 [00:03<00:00, 21.51it/s]\n","Accuracy : 88 %\n","100% 391/391 [00:50<00:00,  7.80it/s]\n","Epoch : 58, Loss Avg : 0.1801\n","100% 79/79 [00:03<00:00, 23.00it/s]\n","Accuracy : 88 %\n","100% 391/391 [00:49<00:00,  7.83it/s]\n","Epoch : 59, Loss Avg : 0.1819\n","100% 79/79 [00:03<00:00, 21.76it/s]\n","Accuracy : 87 %\n","100% 391/391 [00:48<00:00,  7.99it/s]\n","Epoch : 60, Loss Avg : 0.1760\n","100% 79/79 [00:04<00:00, 18.77it/s]\n","Accuracy : 87 %\n","100% 391/391 [00:48<00:00,  8.00it/s]\n","Epoch : 61, Loss Avg : 0.1724\n","100% 79/79 [00:03<00:00, 19.76it/s]\n","Accuracy : 85 %\n","100% 391/391 [00:49<00:00,  7.97it/s]\n","Epoch : 62, Loss Avg : 0.1740\n","100% 79/79 [00:03<00:00, 22.74it/s]\n","Accuracy : 87 %\n","100% 391/391 [00:50<00:00,  7.81it/s]\n","Epoch : 63, Loss Avg : 0.1707\n","100% 79/79 [00:03<00:00, 23.81it/s]\n","Accuracy : 87 %\n","100% 391/391 [00:50<00:00,  7.78it/s]\n","Epoch : 64, Loss Avg : 0.1675\n","100% 79/79 [00:03<00:00, 23.82it/s]\n","Accuracy : 87 %\n","100% 391/391 [00:50<00:00,  7.71it/s]\n","Epoch : 65, Loss Avg : 0.1663\n","100% 79/79 [00:03<00:00, 23.39it/s]\n","Accuracy : 88 %\n","100% 391/391 [00:50<00:00,  7.78it/s]\n","Epoch : 66, Loss Avg : 0.1637\n","100% 79/79 [00:03<00:00, 23.31it/s]\n","Accuracy : 87 %\n","100% 391/391 [00:50<00:00,  7.79it/s]\n","Epoch : 67, Loss Avg : 0.1630\n","100% 79/79 [00:03<00:00, 23.03it/s]\n","Accuracy : 88 %\n","100% 391/391 [00:49<00:00,  7.82it/s]\n","Epoch : 68, Loss Avg : 0.1558\n","100% 79/79 [00:03<00:00, 20.41it/s]\n","Accuracy : 87 %\n","100% 391/391 [00:48<00:00,  8.05it/s]\n","Epoch : 69, Loss Avg : 0.1598\n","100% 79/79 [00:04<00:00, 18.38it/s]\n","Accuracy : 88 %\n","100% 391/391 [00:48<00:00,  8.02it/s]\n","Epoch : 70, Loss Avg : 0.1594\n","100% 79/79 [00:03<00:00, 20.60it/s]\n","Accuracy : 88 %\n","100% 391/391 [00:50<00:00,  7.80it/s]\n","Epoch : 71, Loss Avg : 0.1525\n","100% 79/79 [00:03<00:00, 24.30it/s]\n","Accuracy : 88 %\n","100% 391/391 [00:49<00:00,  7.96it/s]\n","Epoch : 72, Loss Avg : 0.1529\n","100% 79/79 [00:03<00:00, 24.22it/s]\n","Accuracy : 88 %\n","100% 391/391 [00:49<00:00,  7.90it/s]\n","Epoch : 73, Loss Avg : 0.1502\n","100% 79/79 [00:03<00:00, 23.74it/s]\n","Accuracy : 88 %\n","100% 391/391 [00:49<00:00,  7.96it/s]\n","Epoch : 74, Loss Avg : 0.1518\n","100% 79/79 [00:03<00:00, 23.33it/s]\n","Accuracy : 88 %\n","100% 391/391 [00:48<00:00,  8.13it/s]\n","Epoch : 75, Loss Avg : 0.1511\n","100% 79/79 [00:04<00:00, 19.18it/s]\n","Accuracy : 88 %\n","100% 391/391 [00:48<00:00,  8.11it/s]\n","Epoch : 76, Loss Avg : 0.1482\n","100% 79/79 [00:03<00:00, 21.65it/s]\n","Accuracy : 88 %\n","100% 391/391 [00:48<00:00,  8.01it/s]\n","Epoch : 77, Loss Avg : 0.1413\n","100% 79/79 [00:03<00:00, 24.01it/s]\n","Accuracy : 85 %\n","100% 391/391 [00:49<00:00,  7.89it/s]\n","Epoch : 78, Loss Avg : 0.1440\n","100% 79/79 [00:03<00:00, 24.17it/s]\n","Accuracy : 88 %\n","100% 391/391 [00:49<00:00,  7.93it/s]\n","Epoch : 79, Loss Avg : 0.1403\n","100% 79/79 [00:03<00:00, 23.78it/s]\n","Accuracy : 87 %\n","100% 391/391 [00:49<00:00,  7.96it/s]\n","Epoch : 80, Loss Avg : 0.1407\n","100% 79/79 [00:03<00:00, 22.40it/s]\n","Accuracy : 88 %\n","100% 391/391 [00:48<00:00,  8.06it/s]\n","Epoch : 81, Loss Avg : 0.1391\n","100% 79/79 [00:04<00:00, 18.48it/s]\n","Accuracy : 87 %\n","100% 391/391 [00:48<00:00,  8.14it/s]\n","Epoch : 82, Loss Avg : 0.1363\n","100% 79/79 [00:03<00:00, 21.57it/s]\n","Accuracy : 86 %\n","100% 391/391 [00:48<00:00,  8.06it/s]\n","Epoch : 83, Loss Avg : 0.1382\n","100% 79/79 [00:03<00:00, 24.43it/s]\n","Accuracy : 88 %\n","100% 391/391 [00:49<00:00,  7.96it/s]\n","Epoch : 84, Loss Avg : 0.1390\n","100% 79/79 [00:03<00:00, 24.29it/s]\n","Accuracy : 88 %\n","100% 391/391 [00:48<00:00,  7.99it/s]\n","Epoch : 85, Loss Avg : 0.1294\n","100% 79/79 [00:03<00:00, 24.37it/s]\n","Accuracy : 88 %\n","100% 391/391 [00:48<00:00,  8.08it/s]\n","Epoch : 86, Loss Avg : 0.1351\n","100% 79/79 [00:04<00:00, 19.60it/s]\n","Accuracy : 88 %\n","100% 391/391 [00:48<00:00,  8.08it/s]\n","Epoch : 87, Loss Avg : 0.1261\n","100% 79/79 [00:03<00:00, 20.38it/s]\n","Accuracy : 88 %\n","100% 391/391 [00:48<00:00,  8.07it/s]\n","Epoch : 88, Loss Avg : 0.1319\n","100% 79/79 [00:03<00:00, 24.64it/s]\n","Accuracy : 86 %\n","100% 391/391 [00:48<00:00,  8.03it/s]\n","Epoch : 89, Loss Avg : 0.1290\n","100% 79/79 [00:03<00:00, 24.65it/s]\n","Accuracy : 86 %\n","100% 391/391 [00:48<00:00,  8.00it/s]\n","Epoch : 90, Loss Avg : 0.1291\n","100% 79/79 [00:03<00:00, 25.15it/s]\n","Accuracy : 87 %\n","100% 391/391 [00:48<00:00,  8.11it/s]\n","Epoch : 91, Loss Avg : 0.1270\n","100% 79/79 [00:03<00:00, 20.71it/s]\n","Accuracy : 88 %\n"," 55% 216/391 [00:26<00:20,  8.46it/s]"]}]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UmUlRV357tbr","executionInfo":{"status":"ok","timestamp":1690522414959,"user_tz":-540,"elapsed":1450,"user":{"displayName":"논문논문","userId":"03109390045991028253"}},"outputId":"b7a1d75e-c1a3-4bba-bb56-16a1433829ae"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2.5"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":[],"metadata":{"id":"uB297I3l_MQk"},"execution_count":null,"outputs":[]}]}